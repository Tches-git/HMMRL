{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: [(0, {'node': <__main__.GraphNode object at 0x000001886FC11DC0>}), (1, {'node': <__main__.GraphNode object at 0x000001886FBF2550>})]\n",
      "Edges: [(0, 1)]\n"
     ]
    }
   ],
   "source": [
    "# 示例残片特征提取\n",
    "F001_features = {\n",
    "    \"edges\": {\n",
    "        \"e1\":chain_code[0],  # 上边缘曲率序列\n",
    "        \"e2\":chain_code[1], # 下边缘特征\n",
    "        \"e3\":chain_code[2],\n",
    "        \"e4\":chain_code[3]\n",
    "    },\n",
    "    \"text\": {\n",
    "        \"direction\": (\"down\", \"right\"), # 文字主方向向下，次方向向右\n",
    "        \"content\": \"方諸佛難願觀察過去諸佛有扵如是五經...\",\n",
    "        \"BERT_embedding\": \"[0.1, 0.2, ..., 0.5]\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "class GraphNode:\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_id: int,\n",
    "        freeman_codes: Dict[str, List[int]],  # 四个方向的Freeman编码\n",
    "        centroid: Tuple[float, float],       # 质心位置 (x, y)\n",
    "        semantic_vector: Optional[np.ndarray] = None  # BERT语义向量\n",
    "    ):\n",
    "        \"\"\"\n",
    "        图节点类\n",
    "        \n",
    "        参数:\n",
    "            node_id: 节点唯一标识符\n",
    "            freeman_codes: 四个方向的Freeman编码字典，键为方向('top', 'bottom', 'left', 'right')\n",
    "            centroid: 质心坐标(x, y)\n",
    "            semantic_vector: BERT生成的语义向量(可选)\n",
    "        \"\"\"\n",
    "        self.id = node_id\n",
    "        self.freeman_codes = freeman_codes  # 存储四个方向的轮廓特征\n",
    "        self.centroid = centroid            # 质心位置\n",
    "        self.semantic_vector = semantic_vector  # 语义向量\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"GraphNode(id={self.id}, centroid={self.centroid}, freeman_codes={self.freeman_codes})\"\n",
    "\n",
    "class GraphEdge:\n",
    "    def __init__(self, node1: int, node2: int, weight: Optional[float] = None):\n",
    "        \"\"\"\n",
    "        图边类\n",
    "        \n",
    "        参数:\n",
    "            node1: 第一个节点ID\n",
    "            node2: 第二个节点ID\n",
    "            weight: 边权值(可选)\n",
    "        \"\"\"\n",
    "        self.node1 = node1\n",
    "        self.node2 = node2\n",
    "        self.weight = weight\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"GraphEdge({self.node1} <-> {self.node2}, weight={self.weight})\"\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self):\n",
    "        \"\"\"图结构类\"\"\"\n",
    "        self.nodes: Dict[int, GraphNode] = {}\n",
    "        self.edges: List[GraphEdge] = []\n",
    "        self._next_node_id = 0\n",
    "        \n",
    "    def add_node(\n",
    "        self,\n",
    "        freeman_codes: Dict[str, List[int]],\n",
    "        centroid: Tuple[float, float],\n",
    "        text: Optional[str] = None,\n",
    "        bert_model: Optional[BertModel] = None,\n",
    "        bert_tokenizer: Optional[BertTokenizer] = None\n",
    "    ) -> int:\n",
    "        \"\"\"\n",
    "        添加节点到图中\n",
    "        \n",
    "        参数:\n",
    "            freeman_codes: 四个方向的Freeman编码\n",
    "            centroid: 质心位置\n",
    "            text: 用于生成BERT向量的文本(可选)\n",
    "            bert_model: BERT模型(可选)\n",
    "            bert_tokenizer: BERT分词器(可选)\n",
    "            \n",
    "        返回:\n",
    "            新添加节点的ID\n",
    "        \"\"\"\n",
    "        # 生成语义向量(如果提供了文本和BERT模型)\n",
    "        semantic_vector = None\n",
    "        if text is not None and bert_model is not None and bert_tokenizer is not None:\n",
    "            semantic_vector = self._generate_bert_vector(text, bert_model, bert_tokenizer)\n",
    "        \n",
    "        node_id = self._next_node_id\n",
    "        self.nodes[node_id] = GraphNode(node_id, freeman_codes, centroid, semantic_vector)\n",
    "        self._next_node_id += 1\n",
    "        return node_id\n",
    "    \n",
    "    def add_edge(self, node1: int, node2: int, weight: Optional[float] = None):\n",
    "        \"\"\"\n",
    "        添加边到图中\n",
    "        \n",
    "        参数:\n",
    "            node1: 第一个节点ID\n",
    "            node2: 第二个节点ID\n",
    "            weight: 边权值(可选)\n",
    "        \"\"\"\n",
    "        if node1 not in self.nodes or node2 not in self.nodes:\n",
    "            raise ValueError(\"One or both nodes do not exist in the graph\")\n",
    "        self.edges.append(GraphEdge(node1, node2, weight))\n",
    "    \n",
    "    def _generate_bert_vector(\n",
    "        self,\n",
    "        text: str,\n",
    "        bert_model: BertModel,\n",
    "        bert_tokenizer: BertTokenizer\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        使用BERT模型生成文本的语义向量\n",
    "        \n",
    "        参数:\n",
    "            text: 输入文本\n",
    "            bert_model: BERT模型\n",
    "            bert_tokenizer: BERT分词器\n",
    "            \n",
    "        返回:\n",
    "            文本的语义向量(numpy数组)\n",
    "        \"\"\"\n",
    "        # 分词和编码\n",
    "        inputs = bert_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        \n",
    "        # 获取BERT输出\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "        \n",
    "        # 使用[CLS]标记的隐藏状态作为整个文本的表示\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        cls_embedding = last_hidden_states[:, 0, :].numpy()\n",
    "        \n",
    "        return cls_embedding\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Graph(nodes={len(self.nodes)}, edges={len(self.edges)})\"\n",
    "\n",
    "# 示例用法\n",
    "if __name__ == \"__main__\":\n",
    "    # 初始化BERT模型和分词器(如果需要生成语义向量)\n",
    "    bert_model = None\n",
    "    bert_tokenizer = None\n",
    "    # 实际使用时取消下面注释\n",
    "    # from transformers import BertModel, BertTokenizer\n",
    "    # bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    # bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    # 创建图实例\n",
    "    graph = Graph()\n",
    "    \n",
    "    # 添加节点(示例Freeman编码)\n",
    "    node1_id = graph.add_node(\n",
    "        freeman_codes={\n",
    "            'top': [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "            'bottom': [7, 6, 5, 4, 3, 2, 1, 0],\n",
    "            'left': [0, 7, 6, 5],\n",
    "            'right': [4, 3, 2, 1]\n",
    "        },\n",
    "        centroid=(10.5, 20.3),\n",
    "        text=\"This is an example text for node 1\",\n",
    "        bert_model=bert_model,\n",
    "        bert_tokenizer=bert_tokenizer\n",
    "    )\n",
    "    \n",
    "    node2_id = graph.add_node(\n",
    "        freeman_codes={\n",
    "            'top': [7, 6, 5, 4],\n",
    "            'bottom': [3, 2, 1, 0],\n",
    "            'left': [0, 1, 2, 3],\n",
    "            'right': [4, 5, 6, 7]\n",
    "        },\n",
    "        centroid=(15.2, 18.7),\n",
    "        text=\"Another example for node 2\",\n",
    "        bert_model=bert_model,\n",
    "        bert_tokenizer=bert_tokenizer\n",
    "    )\n",
    "    \n",
    "    # 添加边(空权值)\n",
    "    graph.add_edge(node1_id, node2_id)\n",
    "    \n",
    "    # 打印图信息\n",
    "    print(graph)\n",
    "    print(\"Nodes:\")\n",
    "    for node_id, node in graph.nodes.items():\n",
    "        print(f\"  {node}\")\n",
    "        if node.semantic_vector is not None:\n",
    "            print(f\"    Semantic vector shape: {node.semantic_vector.shape}\")\n",
    "    \n",
    "    print(\"Edges:\")\n",
    "    for edge in graph.edges:\n",
    "        print(f\"  {edge}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
