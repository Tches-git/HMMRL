{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from hmmlearn import hmm\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "class GraphNode:\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_id: int,\n",
    "        freeman_codes: Dict[str, List[int]],\n",
    "        centroid: Tuple[float, float],\n",
    "        contour_centroids: List[Tuple[float, float]],\n",
    "        semantic_vector: Optional[np.ndarray] = None,\n",
    "        contours: Optional[List[np.ndarray]] = None,\n",
    "        image_id: Optional[int] = None,\n",
    "        original_image: Optional[np.ndarray] = None\n",
    "    ):\n",
    "        self.id = node_id\n",
    "        self.freeman_codes = freeman_codes\n",
    "        self.centroid = centroid\n",
    "        self.contour_centroids = contour_centroids\n",
    "        self.semantic_vector = semantic_vector\n",
    "        self.contours = contours\n",
    "        self.image_id = image_id\n",
    "        self.original_image = original_image\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"GraphNode(id={self.id}, image_id={self.image_id}, centroid={self.centroid})\"\n",
    "\n",
    "class GraphEdge:\n",
    "    def __init__(self, node1: int, node2: int, weight: Optional[float] = None):\n",
    "        self.node1 = node1\n",
    "        self.node2 = node2\n",
    "        self.weight = weight\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"GraphEdge({self.node1} <-> {self.node2}, weight={self.weight})\"\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self):\n",
    "        self.nodes: Dict[int, GraphNode] = {}\n",
    "        self.edges: List[GraphEdge] = []\n",
    "        self._next_node_id = 0\n",
    "        \n",
    "    def add_node(self, freeman_codes, centroid, contour_centroids, text=None, bert_model=None, bert_tokenizer=None, contours=None, image_id=None, original_image=None):\n",
    "        semantic_vector = None\n",
    "        if text and bert_model and bert_tokenizer:\n",
    "            semantic_vector = self._generate_bert_vector(text, bert_model, bert_tokenizer)\n",
    "        \n",
    "        node_id = self._next_node_id\n",
    "        self.nodes[node_id] = GraphNode(\n",
    "            node_id=node_id,\n",
    "            freeman_codes=freeman_codes,\n",
    "            centroid=centroid,\n",
    "            contour_centroids=contour_centroids,\n",
    "            semantic_vector=semantic_vector,\n",
    "            contours=contours,\n",
    "            image_id=image_id,\n",
    "            original_image=original_image\n",
    "        )\n",
    "        self._next_node_id += 1\n",
    "        return node_id\n",
    "    \n",
    "    def add_edge(self, node1: int, node2: int, weight: Optional[float] = None):\n",
    "        if node1 not in self.nodes or node2 not in self.nodes:\n",
    "            raise ValueError(\"One or both nodes do not exist in the graph\")\n",
    "        self.edges.append(GraphEdge(node1, node2, weight))\n",
    "    \n",
    "    def _generate_bert_vector(self, text, bert_model, bert_tokenizer):\n",
    "        inputs = bert_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "        return outputs.last_hidden_state[:, 0, :].numpy()\n",
    "    \n",
    "    def visualize(self, stitched_image: Optional[np.ndarray] = None):\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        unique_image_ids = set(node.image_id for node in self.nodes.values())\n",
    "        for idx, img_id in enumerate(unique_image_ids, 1):\n",
    "            node = next(n for n in self.nodes.values() if n.image_id == img_id)\n",
    "            original_img = node.original_image\n",
    "            \n",
    "            mask = np.zeros_like(original_img)\n",
    "            cv2.drawContours(mask, [np.vstack(node.contours)], -1, (255), thickness=cv2.FILLED)\n",
    "            fragment = cv2.bitwise_and(original_img, original_img, mask=mask)\n",
    "            \n",
    "            plt.subplot(2, len(unique_image_ids), idx)\n",
    "            plt.imshow(original_img, cmap='gray')\n",
    "            plt.title(f'原始图像 {img_id}')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(2, len(unique_image_ids), idx + len(unique_image_ids))\n",
    "            plt.imshow(fragment, cmap='gray')\n",
    "            plt.title(f'提取的残片 {img_id}')\n",
    "            plt.axis('off')\n",
    "        \n",
    "        if stitched_image is not None:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.imshow(stitched_image, cmap='gray')\n",
    "            plt.title('拼接复原结果')\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "class ContourProcessor:\n",
    "    def process_image(self, image_path: str) -> Tuple[List[np.ndarray], List[List[int]]]:\n",
    "        \"\"\"处理图像并提取轮廓\"\"\"\n",
    "        try:\n",
    "            original = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if original is None:\n",
    "                raise ValueError(f\"无法读取图像: {image_path}\")\n",
    "\n",
    "            processed = self.preprocess(original)\n",
    "            if processed is None:\n",
    "                raise ValueError(\"图像预处理失败\")\n",
    "            \n",
    "            contours, hierarchy = cv2.findContours(processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            if not contours:\n",
    "                raise ValueError(\"未找到任何轮廓\")\n",
    "            \n",
    "            valid_contours = [cnt for cnt in contours if self.is_valid_contour(cnt, original.shape)]\n",
    "            if not valid_contours:\n",
    "                raise ValueError(\"未找到有效轮廓，请调整预处理参数\")\n",
    "\n",
    "            best_contour = max(valid_contours, key=lambda c: cv2.contourArea(c))\n",
    "            perimeter = cv2.arcLength(best_contour, True)\n",
    "            epsilon = 0.01 * perimeter\n",
    "            approx = cv2.approxPolyDP(best_contour, epsilon, True)\n",
    "\n",
    "            for _ in range(20):\n",
    "                if len(approx) == 4:\n",
    "                    break\n",
    "                elif len(approx) > 4:\n",
    "                    epsilon *= 1.1\n",
    "                else:\n",
    "                    epsilon *= 0.9\n",
    "                approx = cv2.approxPolyDP(best_contour, epsilon, True)\n",
    "            \n",
    "            if len(approx) != 4:\n",
    "                raise ValueError(\"无法近似为恰好4个点\")\n",
    "\n",
    "            contour_points = best_contour.reshape(-1, 2)\n",
    "            indices = [np.argmin(np.sum((contour_points - p)**2, axis=1)) \n",
    "                      for p in approx.reshape(-1, 2)]\n",
    "            indices.sort()\n",
    "\n",
    "            if len(set(indices)) != 4:\n",
    "                raise ValueError(\"近似点映射到重复索引\")\n",
    "\n",
    "            segments = [\n",
    "                best_contour[indices[0]:indices[1]+1],\n",
    "                best_contour[indices[1]:indices[2]+1],\n",
    "                best_contour[indices[2]:indices[3]+1],\n",
    "                np.vstack((best_contour[indices[3]:], best_contour[:indices[0]+1]))\n",
    "            ]\n",
    "\n",
    "            chain_codes = [self.freeman_chain_code(seg, closed=False) for seg in segments]\n",
    "            \n",
    "            if len(segments) != 4 or len(chain_codes) != 4:\n",
    "                raise ValueError(\"轮廓分割或链码生成失败\")\n",
    "            \n",
    "            return segments, chain_codes\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"图像处理错误: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def preprocess(self, img):\n",
    "        if img is None:\n",
    "            return None\n",
    "            \n",
    "        blurred = cv2.GaussianBlur(img, (7, 7), 1.5)\n",
    "        thresh = cv2.adaptiveThreshold(\n",
    "            blurred, \n",
    "            255, \n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "            cv2.THRESH_BINARY_INV, \n",
    "            21, \n",
    "            6\n",
    "        )\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "        closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "        return closed\n",
    "\n",
    "    def is_valid_contour(self, cnt, img_shape):\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area < 500:\n",
    "            return False\n",
    "        \n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if (x == 0 or y == 0 or \n",
    "            x + w >= img_shape[1] - 1 or \n",
    "            y + h >= img_shape[0] - 1):\n",
    "            return False\n",
    "        \n",
    "        solidity = area / (w * h)\n",
    "        return 0.3 < solidity < 0.9\n",
    "\n",
    "    def freeman_chain_code(self, contour, closed=True):\n",
    "        directions = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "        dx = [1, 1, 0, -1, -1, -1, 0, 1]\n",
    "        dy = [0, 1, 1, 1, 0, -1, -1, -1]\n",
    "        chain_code = []\n",
    "        n = len(contour)\n",
    "        \n",
    "        for i in range(n - 1 if not closed else n):\n",
    "            current = contour[i % n][0]\n",
    "            next_p = contour[(i + 1) % n][0]\n",
    "            delta = (next_p[0] - current[0], next_p[1] - current[1])\n",
    "            \n",
    "            for j, (ddx, ddy) in enumerate(zip(dx, dy)):\n",
    "                if delta == (ddx, ddy):\n",
    "                    chain_code.append(j)\n",
    "                    break\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid direction delta: {delta} at index {i}\")\n",
    "        \n",
    "        return chain_code\n",
    "\n",
    "    def compute_shape_context(self, contour, n_points=100, n_bins_r=5, n_bins_theta=12):\n",
    "        contour = contour.squeeze()\n",
    "        sampled_points = np.array([\n",
    "            contour[int(i * len(contour) / n_points)] \n",
    "            for i in range(n_points)\n",
    "        ])\n",
    "        \n",
    "        shape_contexts = []\n",
    "        for i in range(n_points):\n",
    "            diff = sampled_points - sampled_points[i]\n",
    "            distances = np.sqrt(np.sum(diff**2, axis=1))\n",
    "            angles = np.arctan2(diff[:, 1], diff[:, 0])\n",
    "            \n",
    "            angles[angles < 0] += 2 * np.pi\n",
    "            \n",
    "            max_dist = distances.max()\n",
    "            min_dist = distances[distances > 0].min()\n",
    "            log_r_bins = np.logspace(np.log10(min_dist), np.log10(max_dist), n_bins_r)\n",
    "            theta_bins = np.linspace(0, 2*np.pi, n_bins_theta+1)\n",
    "            \n",
    "            hist, _, _ = np.histogram2d(\n",
    "                distances, angles, \n",
    "                bins=[log_r_bins, theta_bins]\n",
    "            )\n",
    "            shape_contexts.append(hist.flatten())\n",
    "            \n",
    "        return np.array(shape_contexts)\n",
    "\n",
    "    def dtw_distance(self, seq1, seq2):\n",
    "        n, m = len(seq1), len(seq2)\n",
    "        dtw_matrix = np.inf * np.ones((n + 1, m + 1))\n",
    "        dtw_matrix[0, 0] = 0\n",
    "        \n",
    "        for i in range(1, n + 1):\n",
    "            for j in range(1, m + 1):\n",
    "                cost = np.linalg.norm(seq1[i-1] - seq2[j-1])\n",
    "                dtw_matrix[i, j] = cost + min(\n",
    "                    dtw_matrix[i-1, j],\n",
    "                    dtw_matrix[i, j-1],\n",
    "                    dtw_matrix[i-1, j-1]\n",
    "                )\n",
    "        \n",
    "        return dtw_matrix[n, m]\n",
    "\n",
    "    def evaluate_contour_match(self, contour1, contour2):\n",
    "        try:\n",
    "            contour1 = contour1.squeeze()\n",
    "            contour2 = contour2.squeeze()\n",
    "            \n",
    "            if contour1.ndim != 2 or contour2.ndim != 2:\n",
    "                return 0.0\n",
    "            \n",
    "            if len(contour1) < 5 or len(contour2) < 5:\n",
    "                return 0.0\n",
    "            \n",
    "            sc1 = self.compute_shape_context(contour1)\n",
    "            sc2 = self.compute_shape_context(contour2)\n",
    "            \n",
    "            dtw_dist = self.dtw_distance(sc1, sc2)\n",
    "            \n",
    "            max_possible_dist = np.sqrt(sc1.shape[1])\n",
    "            match_score = 1.0 - (dtw_dist / (max_possible_dist + 1e-5))\n",
    "            \n",
    "            return np.clip(match_score, 0.0, 1.0)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"轮廓匹配计算错误: {str(e)}\")\n",
    "            return 0.0\n",
    "\n",
    "class GraphBuilder:\n",
    "    def __init__(self):\n",
    "        self.graph = Graph()\n",
    "        self._contour_processor = ContourProcessor()\n",
    "    \n",
    "    def build_from_images(self, image_paths, texts=None, bert_model=None, bert_tokenizer=None):\n",
    "        \"\"\"构建图结构并拼接图像\"\"\"\n",
    "        if texts and len(texts) != len(image_paths):\n",
    "            raise ValueError(\"文本数量必须与图像数量匹配\")\n",
    "        \n",
    "        node_ids = []\n",
    "        original_imgs = {}\n",
    "        \n",
    "        # 处理每个输入图像\n",
    "        for img_idx, image_path in enumerate(image_paths):\n",
    "            try:\n",
    "                print(f\"处理图像 {image_path}\")\n",
    "                \n",
    "                original_img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if original_img is None:\n",
    "                    raise ValueError(f\"无法读取图像: {image_path}\")\n",
    "                original_imgs[img_idx] = original_img\n",
    "                \n",
    "                text = texts[img_idx] if texts else None\n",
    "                segments, chain_codes = self._contour_processor.process_image(image_path)\n",
    "                \n",
    "                contour_centroids = [self._compute_centroid(seg) for seg in segments]\n",
    "                all_contour_points = np.vstack(segments)\n",
    "                centroid = self._compute_centroid(all_contour_points)\n",
    "                \n",
    "                freeman_codes = {\n",
    "                    'E1': chain_codes[0],\n",
    "                    'E2': chain_codes[1],\n",
    "                    'E3': chain_codes[2],\n",
    "                    'E4': chain_codes[3]\n",
    "                }\n",
    "                \n",
    "                node_id = self.graph.add_node(\n",
    "                    freeman_codes=freeman_codes,\n",
    "                    centroid=centroid,\n",
    "                    contour_centroids=contour_centroids,\n",
    "                    text=text,\n",
    "                    bert_model=bert_model,\n",
    "                    bert_tokenizer=bert_tokenizer,\n",
    "                    contours=segments,\n",
    "                    image_id=img_idx,\n",
    "                    original_image=original_img\n",
    "                )\n",
    "                node_ids.append(node_id)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"处理图像 {image_path} 时出错: {str(e)}\")\n",
    "                raise\n",
    "\n",
    "        # 计算增强特征并获取最优序列\n",
    "        enhanced_features = self._compute_enhanced_features(node_ids)\n",
    "        optimal_sequence = self._train_hmm_and_get_sequence(enhanced_features, len(image_paths))\n",
    "        stitched_image = self._stitch_images_based_on_sequence(node_ids, optimal_sequence)\n",
    "        \n",
    "        return self.graph, stitched_image\n",
    "\n",
    "    def _compute_centroid(self, contour):\n",
    "        \"\"\"计算轮廓的质心\"\"\"\n",
    "        M = cv2.moments(contour)\n",
    "        cx = int(M['m10'] / (M['m00'] + 1e-5))\n",
    "        cy = int(M['m01'] / (M['m00'] + 1e-5))\n",
    "        return (cx, cy)\n",
    "\n",
    "    def _compute_enhanced_features(self, node_ids):\n",
    "        \"\"\"计算增强的特征向量\"\"\"\n",
    "        n_nodes = len(node_ids)\n",
    "        # 8维特征：4个形状匹配度 + 4个几何特征\n",
    "        features = np.zeros((n_nodes, 8))\n",
    "        \n",
    "        for i, node1_id in enumerate(node_ids):\n",
    "            node1 = self.graph.nodes[node1_id]\n",
    "            shape_scores = np.zeros(4)\n",
    "            geometric_scores = np.zeros(4)\n",
    "            \n",
    "            for j, node2_id in enumerate(node_ids):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                \n",
    "                node2 = self.graph.nodes[node2_id]\n",
    "                \n",
    "                for edge_idx in range(4):\n",
    "                    contour1 = node1.contours[edge_idx]\n",
    "                    contour2 = node2.contours[(edge_idx + 2) % 4]\n",
    "                    \n",
    "                    # 计算形状匹配度\n",
    "                    shape_score = self._contour_processor.evaluate_contour_match(contour1, contour2)\n",
    "                    # 计算几何特征\n",
    "                    geo_score = self._compute_geometric_compatibility(contour1, contour2)\n",
    "                    \n",
    "                    shape_scores[edge_idx] = max(shape_scores[edge_idx], shape_score)\n",
    "                    geometric_scores[edge_idx] = max(geometric_scores[edge_idx], geo_score)\n",
    "            \n",
    "            # 组合特征\n",
    "            features[i] = np.concatenate([shape_scores, geometric_scores])\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def _compute_geometric_compatibility(self, contour1, contour2):\n",
    "        \"\"\"计算两个轮廓的几何兼容性\"\"\"\n",
    "        try:\n",
    "            # 计算轮廓长度\n",
    "            len1 = cv2.arcLength(contour1, False)\n",
    "            len2 = cv2.arcLength(contour2, False)\n",
    "            \n",
    "            # 长度比例相似度\n",
    "            length_ratio = min(len1, len2) / max(len1, len2)\n",
    "            \n",
    "            # 计算方向差异\n",
    "            _, (_, _), angle1 = cv2.fitEllipse(contour1)\n",
    "            _, (_, _), angle2 = cv2.fitEllipse(contour2)\n",
    "            angle_diff = min(abs(angle1 - angle2), 180 - abs(angle1 - angle2)) / 180.0\n",
    "            \n",
    "            # 综合得分\n",
    "            geometric_score = 0.7 * length_ratio + 0.3 * (1 - angle_diff)\n",
    "            return geometric_score\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"几何特征计算错误: {str(e)}\")\n",
    "            return 0.0\n",
    "\n",
    "    def _train_hmm_and_get_sequence(self, observations, n_states):\n",
    "        \"\"\"训练HMM模型并获取序列\"\"\"\n",
    "        try:\n",
    "            n_components = min(n_states, len(observations) - 1)\n",
    "            \n",
    "            model = hmm.GaussianHMM(\n",
    "                n_components=n_components,\n",
    "                covariance_type=\"diag\",\n",
    "                n_iter=100,\n",
    "                init_params=\"\"  # 禁用自动初始化\n",
    "            )\n",
    "            \n",
    "            n_features = observations.shape[1]\n",
    "            \n",
    "            # 初始化起始概率（基于边界特征）\n",
    "            model.startprob_ = self._initialize_start_probabilities(observations, n_components)\n",
    "            \n",
    "            # 初始化改进的转移矩阵\n",
    "            model.transmat_ = self._initialize_transition_matrix(observations, n_components)\n",
    "            \n",
    "            # 初始化均值和协方差\n",
    "            model.means_ = np.zeros((n_components, n_features))\n",
    "            model.covars_ = np.ones((n_components, n_features))\n",
    "            \n",
    "            model.fit(observations)\n",
    "            _, state_sequence = model.decode(observations, algorithm=\"viterbi\")\n",
    "            \n",
    "            return state_sequence\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"HMM训练错误: {str(e)}\")\n",
    "            return np.arange(len(observations))\n",
    "\n",
    "    def _initialize_start_probabilities(self, observations, n_components):\n",
    "        \"\"\"初始化起始概率，考虑边界特征\"\"\"\n",
    "        start_probs = np.zeros(n_components)\n",
    "        \n",
    "        for i in range(n_components):\n",
    "            # 提取边界特征（前4个维度是形状匹配度）\n",
    "            edge_features = observations[i, :4]\n",
    "            \n",
    "            # 计算边界完整性分数（值越小越可能是边界片段）\n",
    "            boundary_score = np.mean(edge_features)\n",
    "            \n",
    "            # 将分数转换为概率\n",
    "            start_probs[i] = 1.0 - boundary_score\n",
    "        \n",
    "        # 归一化\n",
    "        start_probs = np.maximum(start_probs, 1e-5)  # 避免零概率\n",
    "        start_probs /= start_probs.sum()\n",
    "        \n",
    "        return start_probs\n",
    "\n",
    "    def _initialize_transition_matrix(self, observations, n_components):\n",
    "        \"\"\"初始化改进的转移矩阵\"\"\"\n",
    "        transmat = np.zeros((n_components, n_components))\n",
    "        \n",
    "        for i in range(n_components):\n",
    "            for j in range(n_components):\n",
    "                if i != j:\n",
    "                    transmat[i,j] = self._compute_transition_probability(\n",
    "                        observations[i],\n",
    "                        observations[j]\n",
    "                    )\n",
    "        \n",
    "        # 添加自循环惩罚\n",
    "        np.fill_diagonal(transmat, 0.01)\n",
    "        \n",
    "        # 归一化每行\n",
    "        row_sums = transmat.sum(axis=1)\n",
    "        transmat = transmat / row_sums[:, np.newaxis]\n",
    "        \n",
    "        return transmat\n",
    "\n",
    "    def _compute_transition_probability(self, obs1, obs2):\n",
    "        \"\"\"计算两个状态间的转移概率\"\"\"\n",
    "        # 提取特征\n",
    "        shape_scores1 = obs1[:4]  # 形状匹配度\n",
    "        geo_scores1 = obs1[4:8]   # 几何特征\n",
    "        shape_scores2 = obs2[:4]\n",
    "        geo_scores2 = obs2[4:8]\n",
    "        \n",
    "        # 计算边界匹配度\n",
    "        edge_compatibility = self._compute_edge_compatibility(\n",
    "            shape_scores1, shape_scores2,\n",
    "            geo_scores1, geo_scores2\n",
    "        )\n",
    "        \n",
    "        # 计算空间约束\n",
    "        spatial_constraint = self._compute_spatial_constraint(\n",
    "            geo_scores1, geo_scores2\n",
    "        )\n",
    "        \n",
    "        # 计算方向一致性\n",
    "        direction_consistency = self._compute_direction_consistency(\n",
    "            geo_scores1, geo_scores2\n",
    "        )\n",
    "        \n",
    "        # 综合评分\n",
    "        transition_score = (\n",
    "            0.4 * edge_compatibility +\n",
    "            0.3 * spatial_constraint +\n",
    "            0.3 * direction_consistency\n",
    "        )\n",
    "        \n",
    "        return transition_score\n",
    "\n",
    "    def _compute_edge_compatibility(self, shape_scores1, shape_scores2, geo_scores1, geo_scores2):\n",
    "        \"\"\"计算边界匹配度\"\"\"\n",
    "        edge_scores = []\n",
    "        for i in range(4):\n",
    "            opposite_edge = (i + 2) % 4\n",
    "            match_score = (\n",
    "                0.7 * (shape_scores1[i] * shape_scores2[opposite_edge]) +\n",
    "                0.3 * (geo_scores1[i] * geo_scores2[opposite_edge])\n",
    "            )\n",
    "            edge_scores.append(match_score)\n",
    "        \n",
    "        return max(edge_scores)\n",
    "\n",
    "    def _compute_spatial_constraint(self, geo_scores1, geo_scores2):\n",
    "        \"\"\"计算空间约束\"\"\"\n",
    "        length_compatibility = np.minimum(geo_scores1, geo_scores2).mean()\n",
    "        distance_penalty = 1.0\n",
    "        return length_compatibility * distance_penalty\n",
    "\n",
    "    def _compute_direction_consistency(self, geo_scores1, geo_scores2):\n",
    "        \"\"\"计算方向一致性\"\"\"\n",
    "        direction_diff = np.abs(geo_scores1 - geo_scores2)\n",
    "        consistency = 1.0 - np.mean(direction_diff)\n",
    "        return max(0.0, consistency)\n",
    "\n",
    "    def _stitch_images_based_on_sequence(self, node_ids, sequence):\n",
    "        \"\"\"基于序列拼接图像\"\"\"\n",
    "        sorted_indices = np.argsort(sequence)\n",
    "        sorted_nodes = [self.graph.nodes[node_ids[i]] for i in sorted_indices]\n",
    "        \n",
    "        offsets = [(0, 0)]\n",
    "        \n",
    "        for i in range(1, len(sorted_nodes)):\n",
    "            prev_node = sorted_nodes[i-1]\n",
    "            curr_node = sorted_nodes[i]\n",
    "            \n",
    "            best_edge = 0\n",
    "            best_score = 0\n",
    "            for edge_idx in range(4):\n",
    "                contour1 = prev_node.contours[edge_idx]\n",
    "                contour2 = curr_node.contours[(edge_idx + 2) % 4]\n",
    "                score = self._contour_processor.evaluate_contour_match(contour1, contour2)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_edge = edge_idx\n",
    "            \n",
    "            prev_offset = offsets[-1]\n",
    "            contour_length = self._get_contour_length(prev_node.contours[best_edge])\n",
    "            \n",
    "            if best_edge == 0:   # 右\n",
    "                new_offset = (prev_offset[0], prev_offset[1] + contour_length)\n",
    "            elif best_edge == 1: # 下\n",
    "                new_offset = (prev_offset[0] + contour_length, prev_offset[1])\n",
    "            elif best_edge == 2: # 左\n",
    "                new_offset = (prev_offset[0], prev_offset[1] - contour_length)\n",
    "            else:                # 上\n",
    "                new_offset = (prev_offset[0] - contour_length, prev_offset[1])\n",
    "            \n",
    "            offsets.append(new_offset)\n",
    "        \n",
    "        min_x = min(offset[0] for offset in offsets)\n",
    "        min_y = min(offset[1] for offset in offsets)\n",
    "        max_x = max(offset[0] + node.original_image.shape[0] for offset, node in zip(offsets, sorted_nodes))\n",
    "        max_y = max(offset[1] + node.original_image.shape[1] for offset, node in zip(offsets, sorted_nodes))\n",
    "        \n",
    "        canvas_width = int(max_y - min_y)\n",
    "        canvas_height = int(max_x - min_x)\n",
    "        \n",
    "        stitched = np.zeros((canvas_height, canvas_width), dtype=np.uint8)\n",
    "        \n",
    "        for node, offset in zip(sorted_nodes, offsets):\n",
    "            x_pos = int(offset[0] - min_x)\n",
    "            y_pos = int(offset[1] - min_y)\n",
    "            \n",
    "            mask = np.zeros_like(node.original_image)\n",
    "            cv2.drawContours(mask, [np.vstack(node.contours)], -1, (255), thickness=cv2.FILLED)\n",
    "            fragment = cv2.bitwise_and(node.original_image, node.original_image, mask=mask)\n",
    "            \n",
    "            h, w = fragment.shape\n",
    "            x_end = min(x_pos + h, canvas_height)\n",
    "            y_end = min(y_pos + w, canvas_width)\n",
    "            \n",
    "            if x_pos >= 0 and y_pos >= 0 and x_end <= canvas_height and y_end <= canvas_width:\n",
    "                stitched[x_pos:x_end, y_pos:y_end] = np.maximum(\n",
    "                    stitched[x_pos:x_end, y_pos:y_end],\n",
    "                    fragment[:x_end-x_pos, :y_end-y_pos]\n",
    "                )\n",
    "        \n",
    "        return stitched\n",
    "\n",
    "    def _get_contour_length(self, contour):\n",
    "        \"\"\"计算轮廓长度\"\"\"\n",
    "        return int(cv2.arcLength(contour, False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bert_model = None\n",
    "    bert_tokenizer = None\n",
    "    \n",
    "    builder = GraphBuilder()\n",
    "    \n",
    "    image_paths = [\n",
    "        r\"C:\\Users\\28489\\Desktop\\paired\\31\\1.jpg\",\n",
    "        r\"C:\\Users\\28489\\Desktop\\paired\\31\\2.jpg\",\n",
    "        r\"C:\\Users\\28489\\Desktop\\paired\\31\\4.jpg\",\n",
    "        r\"C:\\Users\\28489\\Desktop\\paired\\31\\5.jpg\",\n",
    "        r\"C:\\Users\\28489\\Desktop\\paired\\31\\6.jpg\"\n",
    "    ]\n",
    "    texts = [\"图像1描述\", \"图像2描述\", \"图像4描述\", \"图像5描述\", \"图像6描述\"]\n",
    "    \n",
    "    try:\n",
    "        graph, stitched_image = builder.build_from_images(\n",
    "            image_paths=image_paths,\n",
    "            texts=texts,\n",
    "            bert_model=bert_model,\n",
    "            bert_tokenizer=bert_tokenizer\n",
    "        )\n",
    "        \n",
    "        print(f\"构建的图包含 {len(graph.nodes)} 个节点和 {len(graph.edges)} 条边\")\n",
    "        graph.visualize(stitched_image)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"处理图像时出错: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
